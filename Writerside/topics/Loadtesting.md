# Loadtesting

## Automatic Scaling

Kubernetes can automatically scale the number of pods based on the CPU usage of the pods. To enable this, you can set up a Horizontal Pod Autoscaler (HPA) in Kubernetes. An HPA will automatically scale the number of pods based on the CPU usage of the pods.

### Creating the Autoscaler

I created an autoscaler for the api-gateway deployment. The autoscaler was configured to maintain a CPU utilization of 50%. It could scale the number of pods between 1 and 10 based on the CPU usage.

```Bash
kubectl autoscale deployment api-gateway --cpu-percent=50 --min=1 --max=10
```

### Checking the Autoscaler Status

I checked the current status of the HorizontalPodAutoscaler using the following command:

```Bash
kubectl get hpa
```

It gave me the following output:

```Bash
NAME           REFERENCE                 TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
api-gateway    Deployment/api-gateway    0%/50%   1         10        1          160m
post-service   Deployment/post-service   0%/50%   1         10        1          166m
```

### Creating a Load Generator

To test the autoscaling, I created a load on the api-gateway using a load generator. The load generator was a simple busybox pod running a loop that continuously sent requests to the api-gateway.

```Bash
kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://api-gateway:8080/api/posts; done"
```

### Monitoring the Autoscaler

I monitored the status of the HorizontalPodAutoscaler to see how it reacted to the increased load. I used the --watch flag to get real-time updates.

```Bash
kubectl get hpa api-gateway --watch
```

The output showed the current CPU utilization and the number of pods being scaled up or down in response to the load.

```Bash
NAME           REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
api-gateway    Deployment/api-gateway    1%/50%    1         10        1          16m
post-service   Deployment/post-service   1%/50%    1         10        1          5m54s
api-gateway    Deployment/api-gateway    0%/50%    1         10        1          16m
post-service   Deployment/post-service   16%/50%   1         10        1          6m46s
api-gateway    Deployment/api-gateway    23%/50%   1         10        1          17m
post-service   Deployment/post-service   14%/50%   1         10        1          7m46s
api-gateway    Deployment/api-gateway    19%/50%   1         10        1          18m
post-service   Deployment/post-service   13%/50%   1         10        1          8m46s
api-gateway    Deployment/api-gateway    19%/50%   1         10        1          19m
post-service   Deployment/post-service   14%/50%   1         10        1          9m46s
api-gateway    Deployment/api-gateway    18%/50%   1         10        1          20m
post-service   Deployment/post-service   13%/50%   1         10        1          10m
api-gateway    Deployment/api-gateway    17%/50%   1         10        1          21m
post-service   Deployment/post-service   13%/50%   1         10        1          11m
api-gateway    Deployment/api-gateway    19%/50%   1         10        1          22m
post-service   Deployment/post-service   14%/50%   1         10        1          12m
api-gateway    Deployment/api-gateway    18%/50%   1         10        1          23m
post-service   Deployment/post-service   13%/50%   1         10        1          13m
post-service   Deployment/post-service   14%/50%   1         10        1          14m
api-gateway    Deployment/api-gateway    19%/50%   1         10        1          25m
post-service   Deployment/post-service   18%/50%   1         10        1          15m
api-gateway    Deployment/api-gateway    25%/50%   1         10        1          26m
```

The output shows that the CPU utilization of the api-gateway deployment increased to 25%, which wasn't enough to trigger the autoscaler to scale up the number of pods.

### Checking the Deployment

Finally, I checked the api-gateway deployment to see the number of pods being scaled up or down in response to the load.

```Bash
kubectl get deployment api-gateway
```

This process allowed me to effectively test the scaling of the application within a Minikube environment.

## Postman Local Load Testing

I used Postman desktop application to perform some load testing on the api-gateway which ran in my local Minikube environment. I ran the spike test for 3 minutes with 50 virtual users. These were the results:

Total requests sent
: 3,619

Requests/second
: 19.27

Avg. response time
: 50 ms

These results themselves seem to be fine, but after analyzing the performance graph that's generated by Postman, I noticed an increase in response time during the spike.

![postman_local_loadtest_2.png](postman_local_loadtest_2.png)

The grey line representing the virtual users amount and the blue line representing the response time, we can see that the response time increased as the number of virtual users increased. 

Although it's not a huge spike, since the average response time went from an average of around `13 ms` to an average of `170 ms` during the spike. This might be an early indicator that the application might not be able to handle the load effectively.

The output of the HPA shows that the CPU utilization of the api-gateway deployment increased to 25%, which wasn't enough to trigger the autoscaler to scale up the number of pods. This might be the reason for the increase in response time during the spike.

```Bash
NAME           REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
api-gateway    Deployment/api-gateway    0%/50%    1         10        1          139m
post-service   Deployment/post-service   0%/50%    1         10        1          128m
api-gateway    Deployment/api-gateway    1%/50%    1         10        1          140m
post-service   Deployment/post-service   2%/50%    1         10        1          129m
api-gateway    Deployment/api-gateway    14%/50%   1         10        1          141m
post-service   Deployment/post-service   25%/50%   1         10        1          130m
api-gateway    Deployment/api-gateway    3%/50%    1         10        1          142m
post-service   Deployment/post-service   6%/50%    1         10        1          131m
api-gateway    Deployment/api-gateway    1%/50%    1         10        1          143m
post-service   Deployment/post-service   1%/50%    1         10        1          132m
```